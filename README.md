This project trains a neural net for caption generation.  
This neural network is made of two components: a feed forward convolutional net (CNN) --- to extract features from the images --- and a recurrent neural net (RNN) --- to output a variable length caption for each input image.  
MNIST (handwritten digits) dataset is used for training and testing.
